{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "from entities import *\n",
    "import yaml\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from random import seed\n",
    "import sys\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "from IPython.core.debugger import set_trace\n",
    "import yaml\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_runner(chunk_data,default_params_dict,n_replications, output_folder):\n",
    "    chunk_num, chunk = chunk_data\n",
    "    for i,row in enumerate(chunk):\n",
    "        if i % 1000 == 0:\n",
    "            print chunk_num, i\n",
    "        file_name = output_folder\n",
    "        turn_output_file = open(os.path.join(output_folder,file_name + '{}_detail.tsv'.format(chunk_num)),\"w\")\n",
    "        turn_output_agent_file = open(os.path.join(output_folder,file_name + '{}_agent.tsv'.format(chunk_num)),\"w\")\n",
    "        turn_output_promotion_file = open(os.path.join(output_folder,file_name + '{}_promotion.tsv'.format(chunk_num)),\"w\")\n",
    "        for replication in range(n_replications):\n",
    "            print \"\\t\", replication\n",
    "            #print replication\n",
    "            params_dict = default_params_dict.copy()\n",
    "            params_dict.update(row)\n",
    "            params_dict['replication_number'] = replication\n",
    "            params_dict['run_number'] = int(params_dict['run_number'])\n",
    "            params_dict['turn_output_file'] = turn_output_file\n",
    "            params_dict['turn_output_agent_file'] = turn_output_agent_file\n",
    "            params_dict['turn_output_promotion_file'] = turn_output_promotion_file\n",
    "            run_single_model(params_dict)\n",
    "        turn_output_file.close()\n",
    "        turn_output_agent_file.close()\n",
    "        turn_output_promotion_file.close()\n",
    "\n",
    "\n",
    "def run_single_model(params_dict):\n",
    "    #params_dict['agent_output_file'] = agent_output_file\n",
    "    P = ParameterHolder(params_dict)\n",
    "    # How is agent competence/likeability determined?\n",
    "    agent_promotability_fn = promotability_function_factory(P)\n",
    "    # Functions for new agents\n",
    "    initial_level_sex_fn = sex_function_factory(P, len(P.hierarchy_sizes)-1, 0)\n",
    "    # How agents are promoted\n",
    "    promotion_function = promotion_function_factory(P)\n",
    "    # How agents decide to leave\n",
    "    leave_function = leave_function_factory(P)\n",
    "    assign_projects_fn = assign_projects_factory(P)\n",
    "    agent_id = 0\n",
    "    # Initialize the company\n",
    "    company_hierarchy = []\n",
    "    for level, level_size in enumerate(P.hierarchy_sizes):\n",
    "        sex_fn = sex_function_factory(P, level, 0)\n",
    "        l = []\n",
    "        for _ in range(level_size):\n",
    "            l.append(Agent(sex_function = sex_fn,\n",
    "                            promotability_function=agent_promotability_fn,\n",
    "                            time_of_creation=0,\n",
    "                           id=agent_id))\n",
    "            agent_id +=1\n",
    "        \n",
    "        company_hierarchy.append(l)\n",
    "    # Okay, start the simulation\n",
    "\n",
    "    # For each project cycle\n",
    "    for turn in range(P.n_project_cycles):\n",
    "        #### Print stats about the company\n",
    "#         print_stats(P, turn, company_hierarchy)\n",
    "\n",
    "        # For each hierarchy level\n",
    "        bias_each_level = []\n",
    "        for level_index, company_level in enumerate(company_hierarchy):\n",
    "\n",
    "            # compute the percentage of women at the level\n",
    "            # for bias adjustments\n",
    "            if P.project_bias_type == 'effect_size':\n",
    "                if level_index == 0:\n",
    "                    perc_male = (sum([agent.is_male for agent in company_level]) /\n",
    "                                  float(len(company_level)))\n",
    "                else:\n",
    "                    lookup = company_hierarchy[level_index-1]\n",
    "                    perc_male = (sum([agent.is_male for agent in lookup]) /\n",
    "                                  float(len(lookup)))\n",
    "\n",
    "                proj_success_fn,succ_bias = bias_function_factory(P,perc_male, 'success',turn)\n",
    "                proj_failure_fn,fail_bias = bias_function_factory(P,perc_male, 'fail',turn)\n",
    "                bias_each_level.append(succ_bias)\n",
    "                \n",
    "            else:\n",
    "                if P.project_bias_type =='threshold':\n",
    "                    perc_women = (sum([not agent.is_male for agent in company_level]) /\n",
    "                                  float(len(company_level)))\n",
    "                elif P.project_bias_type == 'micro_macro':\n",
    "                    if level_index == 0:\n",
    "                        perc_women = 0.5\n",
    "                    else:\n",
    "                        lookup = company_hierarchy[level_index-1]\n",
    "                        perc_women = (sum([not agent.is_male for agent in lookup]) /\n",
    "                                  float(len(lookup)))\n",
    "                # What happens on project success and failure?\n",
    "                proj_success_fn = project_function_factory(P,perc_women, 'success')\n",
    "                proj_failure_fn = project_function_factory(P,perc_women, 'fail')\n",
    "\n",
    "            #### Assign Projects\n",
    "            projects = assign_projects_fn(P, company_level, turn, level_index)\n",
    "            #### Carry out the projects\n",
    "            for project in projects:\n",
    "                # Is the project successful? 1 for yes, 0 for no\n",
    "                if project.is_successful:\n",
    "                    for agent in project.agents:\n",
    "                        agent.num_successful_projects += 1\n",
    "                    proj_success_fn(project)\n",
    "                else:\n",
    "                    for agent in project.agents:\n",
    "                        agent.num_failed_projects += 1\n",
    "                    proj_failure_fn(project)\n",
    "        # If its a promotion period\n",
    "        if turn % P.projects_per_promotion_cycle == 0:\n",
    "#             print_agents_each_turn(P,company_hierarchy,turn)\n",
    "            ### Compute the turnover at the company\n",
    "            men_leave,women_leave = [],[]\n",
    "            for level_iter, company_level in enumerate(company_hierarchy):\n",
    "                # See who leaves\n",
    "                leaving_agents, staying_agents = leave_function(P,company_level,level)\n",
    "                # Remove them\n",
    "                company_hierarchy[level_iter] = staying_agents\n",
    "                men_leave.append(len([agent for agent in leaving_agents if agent.is_male]))\n",
    "                women_leave.append(len(leaving_agents) - men_leave[-1])\n",
    "            \n",
    "            men_promoted,women_promoted = [0],[0]\n",
    "            ### Now, promote up, starting at the top\n",
    "            for level_iter in range(len(company_hierarchy)-1):\n",
    "                company_level = company_hierarchy[level_iter]\n",
    "                    # find the top K at the level below me\n",
    "                hire_from = company_hierarchy[level_iter + 1]\n",
    "                current_level = len(company_hierarchy) - level_iter\n",
    "                if P.promotion_intervention and turn >= P.promotion_intervention_span[0] and turn<=P.promotion_intervention_span[1]:\n",
    "                    women_lowerbar = P.hierarchy_sizes[level_iter] * P.promotion_intervention_bar\n",
    "                    women_lowerbar = int(ceil(women_lowerbar))\n",
    "                    women_current = sum([ not i.is_male for i in company_level])\n",
    "                    agents_to_hire,agents_remaining = promotion_function(hire_from,\n",
    "                                                                          P.hierarchy_sizes[level_iter]-len(company_level),\\\n",
    "                                                                         n_women=women_lowerbar-women_current)\n",
    "                else:\n",
    "                     agents_to_hire,agents_remaining = promotion_function(hire_from,\n",
    "                                                                          P.hierarchy_sizes[level_iter]-len(company_level))\n",
    "                men_promoted.append(len([agent for agent in agents_to_hire if agent.is_male]))\n",
    "                women_promoted.append(len([agent for agent in agents_to_hire if not agent.is_male]))\n",
    "                \n",
    "                # promote them\n",
    "                company_hierarchy[level_iter] = company_level + agents_to_hire\n",
    "                # leave the remaining agents\n",
    "                company_hierarchy[level_iter + 1] = agents_remaining     \n",
    "            ### Add new agents to the bottom\n",
    "\n",
    "            new_agents = []\n",
    "            initial_level_sex_fn = sex_function_factory(P, len(P.hierarchy_sizes)-1, turn)\n",
    "\n",
    "            for _ in range(P.hierarchy_sizes[-1] - len(company_hierarchy[-1])):\n",
    "                new_agents.append(Agent(sex_function = initial_level_sex_fn,\n",
    "                                        promotability_function=agent_promotability_fn,\n",
    "                                        time_of_creation=turn,\n",
    "                                        id = agent_id))\n",
    "                agent_id +=1\n",
    "            company_hierarchy[-1] = company_hierarchy[-1] + new_agents\n",
    "            \n",
    "            print_stats_promotion(P, turn, company_hierarchy,men_leave,women_leave,men_promoted,women_promoted, bias_each_level)\n",
    "#             print_agents_each_turn(P,company_hierarchy,turn)\n",
    "    \n",
    "sys.argv = ['','minimal_nodownward.yaml',\n",
    "            'default_params.yaml',\n",
    "            'minimal_threshold_track_promotion_simple_leave',\n",
    "            '100',\n",
    "            '1',\n",
    "            '14260']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: python model.py [path to experiment file]  [path to default params file] [path to desired output folder]   [n_replications_per_condition] [n_cores] [random seed]\n",
      "{'startswith50': [False], 'stretch_project_biased_bar': [1.2], 'downward_causation': [True], 'macro_norm': [0.00498754], 'weight': [0.5], 'promotion_intervention_bar': [0.7], 'leave_function_type': ['simple'], 'promotion_intervention_span': [[168, 240]], 'idv_succ_effect_size': [0.00249377], 'promotion_intervention_norm': [0.4], 'promotion_intervention': [True], 'stretch_intervention_bar': [1], 'stretch_intervention_start': [0], 'project_bias_type': ['effect_size'], 'stretch_project_reward_mean': [30], 'stretch_project_percentage': [0.1], 'stretch_project_biased_assignment': [True], 'idv_fail_effect_size': [0.00249377], 'stretch_intervention': [False], 'external_male_at_above_level': [0.7], 'project_reward_mean': [10], 'mixed_fail_effect_size': [0.00249377], 'project_women_percent_complain_on_mixed_success': [0.1], 'project_assignment_method': ['equalSoloGroupPromotability'], 'project_turns_per_stretch': [12], 'mixed_succ_effect_size': [0.00249377], 'promotability_function_type': ['simple'], 'complaint_bias': [0.9]}\n",
      "1\n",
      "0 0\n",
      "\t0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__main__:11: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "__main__:24: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "__main__:47: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1\n",
      "\t2\n",
      "\t3\n",
      "\t4\n",
      "\t5\n",
      "\t6\n",
      "\t7\n",
      "\t8\n",
      "\t9\n",
      "\t10\n",
      "\t11\n",
      "\t12\n",
      "\t13\n",
      "\t14\n",
      "\t15\n",
      "\t16\n",
      "\t17\n",
      "\t18\n",
      "\t19\n",
      "\t20\n",
      "\t21\n",
      "\t22\n",
      "\t54\n",
      "\t55\n",
      "\t56\n",
      "\t57\n",
      "\t58\n",
      "\t59\n",
      "\t60\n",
      "\t61\n",
      "\t62\n",
      "\t63\n",
      "\t64\n",
      "\t65\n",
      "\t66\n",
      "\t67\n",
      "\t68\n",
      "\t69\n",
      "\t70\n",
      "\t71\n",
      "\t72\n",
      "\t73\n",
      "\t74\n",
      "\t75\n",
      "\t76\n",
      "\t77\n",
      "\t78\n",
      "\t79\n",
      "\t80\n",
      "\t81\n",
      "\t82\n",
      "\t83\n",
      "\t84\n",
      "\t85\n",
      "\t86\n",
      "\t87\n",
      "\t88\n",
      "\t89\n",
      "\t90\n",
      "\t91\n",
      "\t92\n",
      "\t93\n",
      "\t94\n",
      "\t95\n",
      "\t96\n",
      "\t97\n",
      "\t98\n",
      "\t99\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if len(sys.argv) != 6:\n",
    "        print 'Usage: python model.py [path to experiment file] ',\n",
    "        print '[path to default params file] [path to desired output folder] ',\n",
    "        print ' [n_replications_per_condition] [n_cores] [random seed]'\n",
    "\n",
    "\n",
    "    experiment_file, default_params_file, output_folder, n_replications, n_cores, rseed = sys.argv[1:]\n",
    "    \n",
    "    default_params_dict = yaml.load(open(default_params_file))\n",
    "    \n",
    "    seed(int(rseed))\n",
    "    np.random.seed(int(rseed))\n",
    "\n",
    "    n_replications = int(n_replications)\n",
    "    n_cores = int(n_cores)\n",
    "\n",
    "    experiment_details = yaml.load(open(experiment_file))\n",
    "    \n",
    "    print experiment_details\n",
    "    experimental_runs = expand_grid(experiment_details)\n",
    "    experimental_runs = experimental_runs.reset_index().rename(index=str,columns={\"index\":\"run_number\"})\n",
    "\n",
    "    try:\n",
    "        os.mkdir(output_folder)\n",
    "    except:\n",
    "        print \"Not going to overwrite output!\"\n",
    "        #sys.exit(-1)\n",
    "    ## use yaml files\n",
    "    experimental_runs.to_csv(os.path.join(output_folder, \"experiment_details.csv\"),index=False)\n",
    "    experimental_runs = [x[1].to_dict() for x in experimental_runs.iterrows()]\n",
    "    \n",
    "#     ## use previous experiment runs\n",
    "#     experimental_runs = pd.read_csv('./Intervention/experiment_details.csv')\n",
    "#     experimental_runs['stretch_project_biased_assignment'] = False\n",
    "#     experimental_runs = [x[1].to_dict() for x in experimental_runs.iterrows()]\n",
    "    \n",
    "    \n",
    "    print(int(len(experimental_runs) / n_cores))\n",
    "    chunked = list(enumerate(chunkify(experimental_runs, n_cores)))\n",
    "    default_params_dict = yaml.load(open(default_params_file))\n",
    "    runner_partial = partial(model_runner,\n",
    "                             default_params_dict=default_params_dict,\n",
    "                             n_replications=n_replications,\n",
    "                             output_folder=output_folder)\n",
    "    if n_cores > 1:\n",
    "        p = Pool(n_cores)\n",
    "        res = p.map(runner_partial, chunked)\n",
    "        p.close()\n",
    "        p.terminate()\n",
    "    else:\n",
    "        # run on single process\n",
    "        for c in chunked:\n",
    "            runner_partial(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11764706"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-python27]",
   "language": "python",
   "name": "conda-env-miniconda3-python27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
